{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://www.fukushihoken.metro.tokyo.lg.jp/hodo/saishin/hassei.html\n",
    "\n",
    "# TODO\n",
    "* PDFを読み込むとき、数字がくっついてしまうときがある  \n",
    "20210731  20210801_0801-01-01.pdf  \n",
    "20210814  \n",
    "-> char_margin = 1.0 としてみた(デフォは2.0)\n",
    "\n",
    "* データ数が多い日がある(年代別かも)  \n",
    "-> 取得するデータ数を固定にした"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from WebScrapingTool import Base_UserFunction as uf\n",
    "import json\n",
    "import urllib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# https://www.shibutan-bloomers.com/python_library_pdfminer-six/2124/#21PDFJupyterNotebook\n",
    "\n",
    "# getData\n",
    "# 総数\n",
    "# 年代\n",
    "# 都内発生数\n",
    "# 重症者の属性\n",
    "\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import (\n",
    "    LAParams,\n",
    "    LTContainer,\n",
    "    LTTextLine,\n",
    ")\n",
    "from io import StringIO\n",
    "import jaconv\n",
    "from datetime import date\n",
    "from japanera import Japanera, EraDate\n",
    "import unicodedata\n",
    "import copy\n",
    "import math\n",
    "\n",
    "janera = Japanera()\n",
    "\n",
    "SPLITWORD = '@@'\n",
    "\n",
    "def get_objs(layout, results):\n",
    "    if not isinstance(layout, LTContainer):\n",
    "        return\n",
    "    for obj in layout:\n",
    "        if isinstance(obj, LTTextLine):\n",
    "            results.append({'bbox': obj.bbox, 'text' : obj.get_text(), 'type' : type(obj)})\n",
    "        get_objs(obj, results)\n",
    "\n",
    "def readPDF(filePath, type):\n",
    "    pdfList = []\n",
    "    posYSet = set()\n",
    "    with open(filePath, 'rb') as fp:\n",
    "        parser = PDFParser(fp)\n",
    "        document = PDFDocument(parser)\n",
    "        if not document.is_extractable:\n",
    "            raise PDFTextExtractionNotAllowed\n",
    "        laparams = LAParams(\n",
    "            char_margin = 1.0,\n",
    "            all_texts = True,\n",
    "        )\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.create_pages(document):\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            results = []\n",
    "            get_objs(layout, results)\n",
    "            for r in results:\n",
    "#                print(r)\n",
    "                posX1 = r['bbox'][0]\n",
    "                posY1 = r['bbox'][1]\n",
    "                #posX2 = r['bbox'][2]\n",
    "                posY2 = r['bbox'][3]\n",
    "                height = posY2 - posY1\n",
    "                posYCenter = math.floor(posY1 + height / 2)\n",
    "                # ',' '%' ' ' を除外\n",
    "                text = r['text'].replace(',', '').replace('%', '')\n",
    "                text = text.replace(' ', '')\n",
    "                # '(' or ')' -> SPLITWORD\n",
    "                text = text.replace(')', SPLITWORD).replace('(', SPLITWORD)\n",
    "                text = text.replace('\\n', '')\n",
    "                pdfList.append(\n",
    "                    {\n",
    "                    \"posX\" : math.floor(posX1), \n",
    "                    \"posY\" : posYCenter, \n",
    "                    \"height\" : math.floor(height), \n",
    "                    \"text\" : text\n",
    "                    }\n",
    "                )\n",
    "                posYSet.add(posYCenter)\n",
    "\n",
    "            # read only TopPage\n",
    "            break\n",
    "    # sort\n",
    "    # 左から順番にデータを読むため、ソートする\n",
    "    pdfList = sorted(pdfList, key=lambda x:x['posX'])\n",
    "\n",
    "    # 同じY座標のデータ(閾値あり)は一つに統一する\n",
    "    # x, height は最初に見つかった文字のサイズ\n",
    "    mergePdfList = []\n",
    "    range = 5.0\n",
    "    for y in posYSet:\n",
    "        _addDict = {}\n",
    "        isFind = False\n",
    "#        print(\"Target Position \" + str(y))\n",
    "        for l in pdfList:\n",
    "            if l['posY'] >= y - range and l['posY'] <= y + range:\n",
    "#                print(l['text'])\n",
    "                if not isFind:\n",
    "                   _addDict = l.copy()\n",
    "                   isFind = True\n",
    "                else:\n",
    "                    _addDict[\"text\"] = _addDict[\"text\"] + SPLITWORD + l['text']\n",
    "        mergePdfList.append(_addDict)\n",
    "    # sort\n",
    "    mergePdfList = sorted(mergePdfList, key=lambda x:x['posY'], reverse=True)\n",
    "\n",
    "    return mergePdfList\n",
    "\n",
    "def parse(filePath, type):\n",
    "#    print(\"parse start : \" + filePath)\n",
    "    try:\n",
    "        pdfList = readPDF(filePath, type)\n",
    "        #print(pdfList)\n",
    "    except:\n",
    "        return \"file open error... : \" + filePath, False\n",
    "    \n",
    "    modeSokuhouHeader = '別紙'\n",
    "    modeAddHeader = '【追加情報】'\n",
    "    typeAge = 'age'\n",
    "    typeSeriouslyIll = 'seriouslyIll'\n",
    "    # keyword, output Keyword\n",
    "    modeSokuhou = (\n",
    "        ['10歳未満', typeAge],\n",
    "        ['【参考】　重症者の属性', typeSeriouslyIll]\n",
    "    )\n",
    "\n",
    "    modeAdd = (\n",
    "        ['重症者の属性', typeSeriouslyIll],\n",
    "    )\n",
    "\n",
    "    isAdd = False\n",
    "    mode = list()\n",
    "    for l in pdfList:\n",
    "        text = l['text']\n",
    "        if modeSokuhouHeader in text:\n",
    "            mode = copy.deepcopy(modeSokuhou)\n",
    "            break\n",
    "        elif modeAddHeader in text:\n",
    "            isAdd = True\n",
    "            mode = copy.deepcopy(modeAdd)\n",
    "            break\n",
    "\n",
    "    if len(mode) <= 0:\n",
    "        return \"miss match header... : \" + filePath, False\n",
    "\n",
    "    # date\n",
    "    _date = \"\"\n",
    "    for l in pdfList:\n",
    "        text = l['text']\n",
    "        if '◆令和' in text:\n",
    "            _date = jaconv.z2h(text, kana=False, ascii=False, digit=True)\n",
    "            _date = _date.replace('◆', '')\n",
    "            _date = _date[:_date.find('日') + 1]\n",
    "            _date = janera.strptime(_date, \"%-E%-kO年%-km月%-kd日\")\n",
    "            _date = _date[0].strftime('%Y%m%d')\n",
    "            break\n",
    "\n",
    "    if len(_date) <= 0:\n",
    "        return \"missing Date... : \" + filePath, False\n",
    "\n",
    "    tmpDict = dict()\n",
    "    tmpHeader = ''\n",
    "    for m in mode:\n",
    "        w = m[0]\n",
    "        type = m[1]\n",
    "        tmpGetList = list()\n",
    "        isFindKeyWord = False\n",
    "        isFindNumber = False\n",
    "        isEnd = False\n",
    "        for l in pdfList:\n",
    "            text = l['text']\n",
    "            # キーワードを探す\n",
    "            if w in text:\n",
    "                isFindKeyWord = True\n",
    "\n",
    "            # キーワード一致後、数字を探す\n",
    "            if isFindKeyWord:\n",
    "                if not isFindNumber:\n",
    "                    tmp = text.replace('(', SPLITWORD).replace(')', '')\n",
    "                    tmp = tmp.split(SPLITWORD)[0]\n",
    "                    if tmp.encode('utf-8').isdigit():\n",
    "                        isFindNumber = True\n",
    "                    elif tmp.isascii() and '.' in tmp:\n",
    "                        isFindNumber = True\n",
    "                    else:\n",
    "                        # ヘッダーを一時保存(PDFごとに列数が異なるため)\n",
    "                        if type == typeAge:\n",
    "                            tmpHeader = text                        \n",
    "\n",
    "                        elif type == typeSeriouslyIll:\n",
    "                            if not w in text:\n",
    "                                tmpHeader = text                        \n",
    "\n",
    "            # 数字を取得、文字が出てきたら終了\n",
    "            if isFindNumber:\n",
    "                # 年代別を取得するとき、以下の通り分割する\n",
    "                # 10歳未満, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 不明\n",
    "                if type == typeAge:\n",
    "                    tmpList = text.split(SPLITWORD)\n",
    "                    tmpHeader = tmpHeader.replace('10歳未満', 'mi')\n",
    "                    tmpHeader = tmpHeader.replace('100歳以上', 'hu')\n",
    "                    tmpHeader = tmpHeader.replace('不明', 'un')\n",
    "                    tmpHeader = tmpHeader.replace('代', '')\n",
    "                    tmpHeader = tmpHeader.replace(SPLITWORD, '')\n",
    "\n",
    "                    idx = 0\n",
    "                    keyList = ['mi', '10', '20', '30', '40', '50', '60', '70', '80', '90', 'hu', 'un']\n",
    "                    for key in keyList:\n",
    "                        if tmpHeader[0:2] == key:\n",
    "                            tmpGetList.append(tmpList[idx])\n",
    "                            idx += 1\n",
    "                            tmpHeader = tmpHeader[2:]\n",
    "                        else:\n",
    "                            tmpGetList.append('0')\n",
    "                    # データは1行しかないので、必ず終了\n",
    "                    isEnd = True\n",
    "\n",
    "                # 重症者を取得するとき、以下の通り分割する\n",
    "                # 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 確認中, 男, 女, 確認中\n",
    "                elif type == typeSeriouslyIll:\n",
    "                    tmpList = text.split(SPLITWORD)\n",
    "                    tmpHeader = tmpHeader.replace('100', 'hu')\n",
    "                    tmpHeader = tmpHeader.replace('確認中', 'un')\n",
    "                    tmpHeader = tmpHeader.replace('男', 'ma')\n",
    "                    tmpHeader = tmpHeader.replace('女', 'fe')\n",
    "                    tmpHeader = tmpHeader.replace('代', '')\n",
    "                    tmpHeader = tmpHeader.replace(SPLITWORD, '')\n",
    "                    idx = 0\n",
    "                    keyList = ['10', '20', '30', '40', '50', '60', '70', '80', '90', 'hu', 'un', 'ma', 'fe', 'un']\n",
    "                    for key in keyList:\n",
    "                        if tmpHeader[0:2] == key:\n",
    "                            tmpGetList.append(tmpList[idx])\n",
    "                            idx += 1\n",
    "                            tmpHeader = tmpHeader[2:]\n",
    "                        else:\n",
    "                            tmpGetList.append('0')\n",
    "\n",
    "                    #print(tmpHeader)\n",
    "                    #print(tmpList)\n",
    "                    #print(tmpGetList)\n",
    "                    \n",
    "                    # データは1行しかないので、必ず終了\n",
    "                    isEnd = True\n",
    "                \n",
    "                # 今のところここは通らない\n",
    "                else:\n",
    "                    tmpList = text.split(SPLITWORD)\n",
    "                    for tmp in tmpList:\n",
    "                        if tmp.encode('utf-8').isdigit():\n",
    "                            tmpGetList.append(tmp)\n",
    "                        elif tmp.isascii() and '.' in tmp:\n",
    "                            tmpGetList.append(tmp)\n",
    "                        else:\n",
    "                            isEnd = True\n",
    "            if isEnd:\n",
    "                break\n",
    "        tmpDict[w] = tmpGetList\n",
    "\n",
    "    # output \n",
    "    retData = '{'\n",
    "    retData += '\"date\" : \"' + _date + '\", '\n",
    "    retData += '\"isAdd\" : \"' + str(isAdd) + '\", '\n",
    "    for m in mode:\n",
    "        key = m[0]\n",
    "        outputKey = m[1]\n",
    "        tmpDict[key]\n",
    "        retData += '\"' + outputKey + '\" : \"' + ','.join(tmpDict[key]) + '\", '\n",
    "    retData = retData[:-2]\n",
    "    retData = retData + '}'\n",
    "    return retData, True\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def main():\r\n",
    "    print(\"\\n[Start]\"  + uf.getNowTime() + '\\n')\r\n",
    "\r\n",
    "    #設定ファイルから必要な情報を取得する\r\n",
    "    #タグ\r\n",
    "    tag_debug = '[a]'\r\n",
    "    tag_saveFolder = '[b]'\r\n",
    "    tag_loadPDFFolder = '[B]'\r\n",
    "    tag_loadFileName = '[c]'\r\n",
    "    tag_saveFileName = '[j]'\r\n",
    "    tag_parseLogName = '[o]'\r\n",
    "    \r\n",
    "    isDebug = False\r\n",
    "    _saveFolder = ''\r\n",
    "    _loadPDFFolder = ''\r\n",
    "    _loadFileName = ''\r\n",
    "    _saveFileName = ''\r\n",
    "    _parseLogName = ''\r\n",
    "\r\n",
    "    # カレントディレクトリ取得\r\n",
    "    currentDir = '/'\r\n",
    "    try:\r\n",
    "        # Node-RED から呼び出し\r\n",
    "        currentDir = os.path.dirname(__file__) + '/'\r\n",
    "    except:\r\n",
    "        # jupyterNotebook から呼び出し\r\n",
    "        currentDir = os.path.dirname(os.path.abspath(\"__file__\")) + '/'\r\n",
    "    print(currentDir)\r\n",
    "\r\n",
    "    try:\r\n",
    "        with open(currentDir + '_Setting.txt', mode='r') as f:\r\n",
    "            lines = f.readlines()\r\n",
    "            for l in lines:\r\n",
    "                if l.startswith(tag_debug, 0, 3):\r\n",
    "                    if (l.replace(tag_debug, '').rstrip()).lower() == 'true':\r\n",
    "                        isDebug = True\r\n",
    "                    else:\r\n",
    "                        isDebug = False                    \r\n",
    "\r\n",
    "                if l.startswith(tag_saveFolder, 0, 3):\r\n",
    "                    _saveFolder = currentDir + l.replace(tag_saveFolder, '').rstrip()\r\n",
    "             \r\n",
    "                if l.startswith(tag_loadPDFFolder, 0, 3):\r\n",
    "                    _loadPDFFolder = currentDir + l.replace(tag_loadPDFFolder, '').rstrip()\r\n",
    "             \r\n",
    "                if l.startswith(tag_loadFileName, 0, 3):\r\n",
    "                    _loadFileName = l.replace(tag_loadFileName, '').rstrip()\r\n",
    "             \r\n",
    "                if l.startswith(tag_saveFileName, 0, 3):\r\n",
    "                    _saveFileName = l.replace(tag_saveFileName, '').rstrip()\r\n",
    "             \r\n",
    "                if l.startswith(tag_parseLogName, 0, 3):\r\n",
    "                    _parseLogName = l.replace(tag_parseLogName, '').rstrip()\r\n",
    "             \r\n",
    "    except:\r\n",
    "        print('[!!!ERROR!!!] Read Setting.text')\r\n",
    "        return        \r\n",
    "    \r\n",
    "    if len(_saveFolder) <= 0:\r\n",
    "        print('[!!!ERROR!!!] Image data storage folder is None!')\r\n",
    "        return  \r\n",
    "\r\n",
    "    baseFile =_saveFolder + \"/\" + _loadFileName\r\n",
    "    print(baseFile)\r\n",
    "\r\n",
    "    saveFile =_saveFolder + \"/\" + _saveFileName\r\n",
    "    print(saveFile)\r\n",
    "    \r\n",
    "    _parseLogName = _parseLogName.replace('DATE', uf.getNowTime())\r\n",
    "    logFile =_saveFolder + \"/\" + _parseLogName\r\n",
    "    print(logFile)\r\n",
    "    \r\n",
    "    with open(logFile, mode='w') as f:\r\n",
    "        uf.fileWrite(f, uf.getNowTime() + '\\n') \r\n",
    "\r\n",
    "    # ファイルを開く\r\n",
    "    updateList = list()\r\n",
    "    parseList = list()\r\n",
    "    with open(baseFile, mode='r') as f:\r\n",
    "        cnt = 0\r\n",
    "        for line in f:\r\n",
    "            l = line\r\n",
    "            j = json.loads(line)\r\n",
    "            type = j['type']\r\n",
    "            fileName = j['name']\r\n",
    "            isParse = j['isParse']\r\n",
    "            if isParse == \"False\":\r\n",
    "                _data, isGet = parse(_loadPDFFolder + \"/\" + fileName, type)\r\n",
    "                with open(logFile, mode='a') as flog:\r\n",
    "                    uf.fileWrite(flog, uf.getNowTime() + \"\\t\" + fileName + \"\\t\" + _data  + '\\n')                 \r\n",
    "                if not isGet:\r\n",
    "                    continue\r\n",
    "                parseList.append(_data + \"\\n\")\r\n",
    "                cnt += 1\r\n",
    "                print(\"...Parse PDF : \" + fileName + '  ' + str(cnt))\r\n",
    "                l = l.replace('\"isParse\" : \"False\"', '\"isParse\" : \"True\"')\r\n",
    "            updateList.append(l)\r\n",
    "\r\n",
    "        print('\\n...Get Size :' + str(cnt) + '\\n')\r\n",
    "\r\n",
    "    # ファイル更新\r\n",
    "    with open(baseFile, mode='w') as f:\r\n",
    "        for line in updateList:\r\n",
    "                uf.fileWrite(f, line)\r\n",
    "\r\n",
    "    # パースしたデータを追加\r\n",
    "    with open(saveFile, mode='a') as f:\r\n",
    "        for line in parseList:\r\n",
    "                uf.fileWrite(f, line)\r\n",
    "    # 重複データ削除\r\n",
    "    uf.fileDataSlim(saveFile) \r\n",
    "\r\n",
    "    print(\"\\n[ End ]\"  + uf.getNowTime() + '\\n')\r\n",
    "    \r\n",
    "    \r\n",
    "if __name__ == '__main__':\r\n",
    "    main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[Start]20210904215452\n",
      "\n",
      "D:\\#WorkSpace\\ReadCovid-19/\n",
      "D:\\#WorkSpace\\ReadCovid-19/list/dataList.json\n",
      "D:\\#WorkSpace\\ReadCovid-19/list/parsePDF.json\n",
      "D:\\#WorkSpace\\ReadCovid-19/list/parse_20210904215452.log\n",
      "...Parse PDF : 20210904_01_00.pdf  1\n",
      "...Parse PDF : 20210901_0901-20-02.pdf  2\n",
      "...Parse PDF : corona2435.files2435.pdf  3\n",
      "...Parse PDF : 20210903_0903-20-02.pdf  4\n",
      "...Parse PDF : 20210904_01_01.pdf  5\n",
      "...Parse PDF : corona2428.files2428-2.pdf  6\n",
      "...Parse PDF : corona2432.files2432-2.pdf  7\n",
      "...Parse PDF : corona2428.files2428.pdf  8\n",
      "...Parse PDF : 20210903_0903-20-01.pdf  9\n",
      "...Parse PDF : 20210901_0901-20-01.pdf  10\n",
      "...Parse PDF : corona2432.files2432.pdf  11\n",
      "...Parse PDF : 20210902_0902-20-02.pdf  12\n",
      "...Parse PDF : 20210902_0902-20-01.pdf  13\n",
      "...Parse PDF : corona2435.files2435-2.pdf  14\n",
      "\n",
      "...Get Size :14\n",
      "\n",
      "\n",
      "[ End ]20210904215549\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f58e4e82543d0cd2d619c0cff608aeecaf29525f81c9c30d530b5f9f1bf488f9"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}