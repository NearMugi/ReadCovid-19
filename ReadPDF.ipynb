{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://www.fukushihoken.metro.tokyo.lg.jp/hodo/saishin/hassei.html\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from WebScrapingTool import Base_UserFunction as uf\r\n",
    "import json\r\n",
    "import urllib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# https://www.shibutan-bloomers.com/python_library_pdfminer-six/2124/#21PDFJupyterNotebook\r\n",
    "\r\n",
    "# getData\r\n",
    "# 総数\r\n",
    "# 年代\r\n",
    "# 都内発生数\r\n",
    "# 重症者の属性\r\n",
    "\r\n",
    "from pdfminer.pdfparser import PDFParser\r\n",
    "from pdfminer.pdfdocument import PDFDocument\r\n",
    "from pdfminer.pdfpage import PDFPage\r\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\r\n",
    "from pdfminer.pdfinterp import PDFResourceManager\r\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\r\n",
    "from pdfminer.converter import PDFPageAggregator\r\n",
    "from pdfminer.layout import (\r\n",
    "    LAParams,\r\n",
    "    LTContainer,\r\n",
    "    LTTextLine,\r\n",
    ")\r\n",
    "from io import StringIO\r\n",
    "import jaconv\r\n",
    "from datetime import date\r\n",
    "from japanera import Japanera, EraDate\r\n",
    "import unicodedata\r\n",
    "import copy\r\n",
    "import math\r\n",
    "\r\n",
    "janera = Japanera()\r\n",
    "\r\n",
    "SPLITWORD = '@@'\r\n",
    "\r\n",
    "def get_objs(layout, results):\r\n",
    "    if not isinstance(layout, LTContainer):\r\n",
    "        return\r\n",
    "    for obj in layout:\r\n",
    "        if isinstance(obj, LTTextLine):\r\n",
    "            results.append({'bbox': obj.bbox, 'text' : obj.get_text(), 'type' : type(obj)})\r\n",
    "        get_objs(obj, results)\r\n",
    "\r\n",
    "def readPDF(filePath, type):\r\n",
    "    pdfList = []\r\n",
    "    posYSet = set()\r\n",
    "    with open(filePath, 'rb') as fp:\r\n",
    "        parser = PDFParser(fp)\r\n",
    "        document = PDFDocument(parser)\r\n",
    "        if not document.is_extractable:\r\n",
    "            raise PDFTextExtractionNotAllowed\r\n",
    "        # https://pdfminersix.readthedocs.io/en/latest/api/composable.html#\r\n",
    "        laparams = LAParams(\r\n",
    "            all_texts=True,\r\n",
    "        )\r\n",
    "        rsrcmgr = PDFResourceManager()\r\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\r\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\r\n",
    "        for page in PDFPage.create_pages(document):\r\n",
    "            interpreter.process_page(page)\r\n",
    "            layout = device.get_result()\r\n",
    "            results = []\r\n",
    "            get_objs(layout, results)\r\n",
    "            for r in results:\r\n",
    "#                print(r)\r\n",
    "                posX1 = r['bbox'][0]\r\n",
    "                posY1 = r['bbox'][1]\r\n",
    "                #posX2 = r['bbox'][2]\r\n",
    "                posY2 = r['bbox'][3]\r\n",
    "                height = posY2 - posY1\r\n",
    "                posYCenter = math.floor(posY1 + height / 2)\r\n",
    "                # ',' '%' ' ' を除外\r\n",
    "                text = r['text'].replace(',', '').replace('%', '')\r\n",
    "                text = text.replace(' ', '')\r\n",
    "                # '(' or ')' -> SPLITWORD\r\n",
    "                text = text.replace(')', SPLITWORD).replace('(', SPLITWORD)\r\n",
    "                text = text.replace('\\n', '')\r\n",
    "                pdfList.append(\r\n",
    "                    {\r\n",
    "                    \"posX\" : math.floor(posX1), \r\n",
    "                    \"posY\" : posYCenter, \r\n",
    "                    \"height\" : math.floor(height), \r\n",
    "                    \"text\" : text\r\n",
    "                    }\r\n",
    "                )\r\n",
    "                posYSet.add(posYCenter)\r\n",
    "\r\n",
    "            # read only TopPage\r\n",
    "            break\r\n",
    "    # sort\r\n",
    "    # 左から順番にデータを読むため、ソートする\r\n",
    "    pdfList = sorted(pdfList, key=lambda x:x['posX'])\r\n",
    "\r\n",
    "    # 同じY座標のデータ(閾値あり)は一つに統一する\r\n",
    "    # x, height は最初に見つかった文字のサイズ\r\n",
    "    mergePdfList = []\r\n",
    "    range = 5.0\r\n",
    "    for y in posYSet:\r\n",
    "        _addDict = {}\r\n",
    "        isFind = False\r\n",
    "#        print(\"Target Position \" + str(y))\r\n",
    "        for l in pdfList:\r\n",
    "            if l['posY'] >= y - range and l['posY'] <= y + range:\r\n",
    "#                print(l['text'])\r\n",
    "                if not isFind:\r\n",
    "                   _addDict = l.copy()\r\n",
    "                   isFind = True\r\n",
    "                else:\r\n",
    "                    _addDict[\"text\"] = _addDict[\"text\"] + SPLITWORD + l['text']\r\n",
    "        mergePdfList.append(_addDict)\r\n",
    "    # sort\r\n",
    "    mergePdfList = sorted(mergePdfList, key=lambda x:x['posY'], reverse=True)\r\n",
    "\r\n",
    "    return mergePdfList\r\n",
    "\r\n",
    "def parse(filePath, type):\r\n",
    "#    print(\"parse start : \" + filePath)\r\n",
    "    getText = ''\r\n",
    "    try:\r\n",
    "        pdfList = readPDF(filePath, type)\r\n",
    "        #print(pdfList)\r\n",
    "    except:\r\n",
    "        return \"file open error... : \" + filePath, False\r\n",
    "\r\n",
    "    modeSokuhouHeader = '別紙'\r\n",
    "    modeAddHeader = '【追加情報】'\r\n",
    "\r\n",
    "    # keyword, Number Count, output StartPos\r\n",
    "    modeSokuhou = (\r\n",
    "#        ['総数', 9, 0],  \r\n",
    "        ['10歳未満', 12, 0],\r\n",
    "        ['【参考】　重症者の属性', 12, 12]\r\n",
    "#        ['都内発生数', 2, 21],\r\n",
    "#        ['千代田', 22, 23],\r\n",
    "#        ['世田谷', 22, 45],\r\n",
    "#        ['江戸川', 22, 67],\r\n",
    "#        ['小平', 22, 89], \r\n",
    "#        ['多摩', 22, 111], \r\n",
    "#        ['新島', 18, 133], \r\n",
    "    )\r\n",
    "\r\n",
    "    modeAdd = (\r\n",
    "#        ['総数（累計）', 8, 0],  \r\n",
    "        ['重症者の属性', 10, 0],\r\n",
    "    )\r\n",
    "\r\n",
    "    modeSokuhouSize = 22\r\n",
    "    modeAddSize = 10\r\n",
    "\r\n",
    "    isAdd = False\r\n",
    "    mode = list()\r\n",
    "    outputSize = 0\r\n",
    "    for l in pdfList:\r\n",
    "        text = l['text']\r\n",
    "        if modeSokuhouHeader in text:\r\n",
    "            mode = copy.deepcopy(modeSokuhou)\r\n",
    "            outputSize = modeSokuhouSize\r\n",
    "            break\r\n",
    "        elif modeAddHeader in text:\r\n",
    "            isAdd = True\r\n",
    "            mode = copy.deepcopy(modeAdd)\r\n",
    "            outputSize = modeAddSize\r\n",
    "            break\r\n",
    "\r\n",
    "    if len(mode) <= 0:\r\n",
    "        return \"miss match header... : \" + filePath, False\r\n",
    "\r\n",
    "    # date\r\n",
    "    _date = \"\"\r\n",
    "    for l in pdfList:\r\n",
    "        text = l['text']\r\n",
    "        if '◆令和' in text:\r\n",
    "            _date = jaconv.z2h(text, kana=False, ascii=False, digit=True)\r\n",
    "            _date = _date.replace('◆', '')\r\n",
    "            _date = _date[:_date.find('日') + 1]\r\n",
    "            _date = janera.strptime(_date, \"%-E%-kO年%-km月%-kd日\")\r\n",
    "            _date = _date[0].strftime('%Y%m%d')\r\n",
    "            break\r\n",
    "\r\n",
    "    if len(_date) <= 0:\r\n",
    "        return \"missing Date... : \" + filePath, False\r\n",
    "\r\n",
    "    tmpDict = dict()\r\n",
    "    for m in mode:\r\n",
    "        w = m[0]\r\n",
    "        tmpGetList = list()\r\n",
    "        isFindKeyWord = False\r\n",
    "        isFindNumber = False\r\n",
    "        isEnd = False\r\n",
    "        for l in pdfList:\r\n",
    "            text = l['text']\r\n",
    "            # キーワードを探す\r\n",
    "            if w in text:\r\n",
    "                isFindKeyWord = True\r\n",
    "\r\n",
    "            # キーワード一致後、数字を探す\r\n",
    "            if isFindKeyWord:\r\n",
    "                if not isFindNumber:\r\n",
    "                    tmp = text.replace('(', SPLITWORD).replace(')', '')\r\n",
    "                    tmp = tmp.split(SPLITWORD)[0]\r\n",
    "                    if tmp.encode('utf-8').isdigit():\r\n",
    "                        isFindNumber = True\r\n",
    "                    elif tmp.isascii() and '.' in tmp:\r\n",
    "                        isFindNumber = True\r\n",
    "                    else:\r\n",
    "                        # ヘッダーも保存(PDFごとに列数が異なるため)\r\n",
    "                        if w == '【参考】　重症者の属性':\r\n",
    "                            if not w in text:\r\n",
    "                                tmpGetList.append(text)                        \r\n",
    "\r\n",
    "            # 数字を取得、文字が出てきたら終了\r\n",
    "            if isFindNumber:\r\n",
    "                tmpList = text.split(SPLITWORD)\r\n",
    "                for tmp in tmpList:\r\n",
    "                    if tmp.encode('utf-8').isdigit():\r\n",
    "                        tmpGetList.append(tmp)\r\n",
    "                    elif tmp.isascii() and '.' in tmp:\r\n",
    "                        tmpGetList.append(tmp)\r\n",
    "                    else:\r\n",
    "                        isEnd = True\r\n",
    "            if isEnd:\r\n",
    "                break\r\n",
    "        tmpDict[w] = tmpGetList\r\n",
    "\r\n",
    "    # output \r\n",
    "    tmpOutputList = [\"\" for i in range(1,outputSize)]\r\n",
    "    for m in mode:\r\n",
    "        key = m[0]\r\n",
    "        size = m[1]\r\n",
    "        startPos = m[2]\r\n",
    "        if key == '総数':\r\n",
    "            # データ並び替え\r\n",
    "            tmpOutputList[startPos :  startPos + size - 1] = tmpDict[key][1:]\r\n",
    "            tmpOutputList[startPos + 6] = tmpDict[key][0]\r\n",
    "            tmpOutputList[startPos + 7] = tmpDict[key][8]\r\n",
    "            tmpOutputList[startPos + 8] = tmpDict[key][7]\r\n",
    "        else:\r\n",
    "            tmpOutputList[startPos : startPos + size - 1] = tmpDict[key]\r\n",
    "    getData = ','.join(tmpOutputList)\r\n",
    "    retData = '{'\r\n",
    "    retData += '\"date\" : \"' + _date + '\", '\r\n",
    "    retData += '\"isAdd\" : \"' + str(isAdd) + '\", '\r\n",
    "    retData += '\"getData\" : \"' + getData\r\n",
    "    retData = retData + '\"}'\r\n",
    "#    print(retData)\r\n",
    "\r\n",
    "    return retData, True\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def main():\r\n",
    "    print(\"\\n[Start]\"  + uf.getNowTime() + '\\n')\r\n",
    "\r\n",
    "    #設定ファイルから必要な情報を取得する\r\n",
    "    #タグ\r\n",
    "    tag_debug = '[a]'\r\n",
    "    tag_saveFolder = '[b]'\r\n",
    "    tag_loadFileName = '[c]'\r\n",
    "    tag_saveFileName = '[j]'\r\n",
    "    tag_parseLogName = '[o]'\r\n",
    "    \r\n",
    "    isDebug = False\r\n",
    "    _saveFolder = ''\r\n",
    "    _loadFileName = ''\r\n",
    "    _saveFileName = ''\r\n",
    "    _parseLogName = ''\r\n",
    "    \r\n",
    "    try:\r\n",
    "        with open('_Setting.txt', mode='r') as f:\r\n",
    "            lines = f.readlines()\r\n",
    "            for l in lines:\r\n",
    "                if l.startswith(tag_debug, 0, 3):\r\n",
    "                    if (l.replace(tag_debug, '').rstrip()).lower() == 'true':\r\n",
    "                        isDebug = True\r\n",
    "                    else:\r\n",
    "                        isDebug = False                    \r\n",
    "\r\n",
    "                if l.startswith(tag_saveFolder, 0, 3):\r\n",
    "                    _saveFolder = l.replace(tag_saveFolder, '').rstrip()\r\n",
    "             \r\n",
    "                if l.startswith(tag_loadFileName, 0, 3):\r\n",
    "                    _loadFileName = l.replace(tag_loadFileName, '').rstrip()\r\n",
    "             \r\n",
    "                if l.startswith(tag_saveFileName, 0, 3):\r\n",
    "                    _saveFileName = l.replace(tag_saveFileName, '').rstrip()\r\n",
    "             \r\n",
    "                if l.startswith(tag_parseLogName, 0, 3):\r\n",
    "                    _parseLogName = l.replace(tag_parseLogName, '').rstrip()\r\n",
    "             \r\n",
    "    except:\r\n",
    "        print('[!!!ERROR!!!] Read Setting.text')\r\n",
    "        return        \r\n",
    "    \r\n",
    "    if len(_saveFolder) <= 0:\r\n",
    "        print('[!!!ERROR!!!] Image data storage folder is None!')\r\n",
    "        return  \r\n",
    "\r\n",
    "    baseFile =_saveFolder + \"/\" + _loadFileName\r\n",
    "    print(baseFile)\r\n",
    "\r\n",
    "    saveFile =_saveFolder + \"/\" + _saveFileName\r\n",
    "    print(saveFile)\r\n",
    "    \r\n",
    "    logFile =_saveFolder + \"/\" + _parseLogName\r\n",
    "    print(logFile)\r\n",
    "    \r\n",
    "    with open(logFile, mode='w') as f:\r\n",
    "        uf.fileWrite(f, uf.getNowTime() + '\\n') \r\n",
    "\r\n",
    "    # ファイルを開く\r\n",
    "    updateList = list()\r\n",
    "    parseList = list()\r\n",
    "    with open(baseFile, mode='r') as f:\r\n",
    "        cnt = 0\r\n",
    "        for line in f:\r\n",
    "            l = line\r\n",
    "            j = json.loads(line)\r\n",
    "            type = j['type']\r\n",
    "            fileName = j['name']\r\n",
    "            isParse = j['isParse']\r\n",
    "            if isParse == \"False\":\r\n",
    "                _data, isGet = parse(_saveFolder + \"/\" + fileName, type)\r\n",
    "                with open(logFile, mode='a') as flog:\r\n",
    "                    uf.fileWrite(flog, uf.getNowTime() + \"\\t\" + fileName + \"\\t\" + _data  + '\\n')                 \r\n",
    "                if not isGet:\r\n",
    "                    continue\r\n",
    "                parseList.append(_data + \"\\n\")\r\n",
    "                cnt += 1\r\n",
    "#                print(\"...Parse PDF : \" + fileName + '  ' + str(cnt))\r\n",
    "#                l = l.replace('\"isParse\" : \"False\"', '\"isParse\" : \"True\"')\r\n",
    "            updateList.append(l)\r\n",
    "\r\n",
    "        print('\\n...Get Size :' + str(cnt) + '\\n')\r\n",
    "\r\n",
    "    # ファイル更新\r\n",
    "    with open(baseFile, mode='w') as f:\r\n",
    "        for line in updateList:\r\n",
    "                uf.fileWrite(f, line)\r\n",
    "\r\n",
    "    # パースしたデータを追加\r\n",
    "    with open(saveFile, mode='a') as f:\r\n",
    "        for line in parseList:\r\n",
    "                uf.fileWrite(f, line)\r\n",
    "    # 重複データ削除\r\n",
    "    uf.fileDataSlim(saveFile) \r\n",
    "\r\n",
    "    print(\"\\n[ End ]\"  + uf.getNowTime() + '\\n')\r\n",
    "    \r\n",
    "    \r\n",
    "if __name__ == '__main__':\r\n",
    "    main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[Start]20210808144841\n",
      "\n",
      "#data/dataList.json\n",
      "#data/parsePDF.json\n",
      "#data/parse.log\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "interpreter": {
   "hash": "f58e4e82543d0cd2d619c0cff608aeecaf29525f81c9c30d530b5f9f1bf488f9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}