{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.fukushihoken.metro.tokyo.lg.jp/hodo/saishin/hassei.html\n",
    "\n",
    "# TODO\n",
    "* PDFを読み込むとき、数字がくっついてしまうときがある  \n",
    "20210731  20210801_0801-01-01.pdf  \n",
    "20210814  \n",
    "-> char_margin = 1.0 としてみた(デフォは2.0)\n",
    "\n",
    "* データ数が多い日がある(年代別かも)  \n",
    "-> 取得するデータ数を固定にした"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from WebScrapingTool import Base_UserFunction as uf\n",
    "import comFunction\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.shibutan-bloomers.com/python_library_pdfminer-six/2124/#21PDFJupyterNotebook\n",
    "\n",
    "# getData\n",
    "# 総数\n",
    "# 年代\n",
    "# 都内発生数\n",
    "# 重症者の属性\n",
    "\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import (\n",
    "    LAParams,\n",
    "    LTContainer,\n",
    "    LTTextLine,\n",
    ")\n",
    "from io import StringIO\n",
    "import jaconv\n",
    "from datetime import date\n",
    "from japanera import Japanera, EraDate\n",
    "import unicodedata\n",
    "import copy\n",
    "import math\n",
    "com = comFunction.common()\n",
    "\n",
    "janera = Japanera()\n",
    "\n",
    "SPLITWORD = '@@'\n",
    "\n",
    "def get_objs(layout, results):\n",
    "    if not isinstance(layout, LTContainer):\n",
    "        return\n",
    "    for obj in layout:\n",
    "        if isinstance(obj, LTTextLine):\n",
    "            results.append({'bbox': obj.bbox, 'text' : obj.get_text(), 'type' : type(obj)})\n",
    "        get_objs(obj, results)\n",
    "\n",
    "def readPDF(filePath, type):\n",
    "    pdfList = []\n",
    "    posYSet = set()\n",
    "    with open(filePath, 'rb') as fp:\n",
    "        parser = PDFParser(fp)\n",
    "        document = PDFDocument(parser)\n",
    "        if not document.is_extractable:\n",
    "            raise PDFTextExtractionNotAllowed\n",
    "        laparams = LAParams(\n",
    "            char_margin = 1.0,\n",
    "            all_texts = True,\n",
    "        )\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "        for page in PDFPage.create_pages(document):\n",
    "            interpreter.process_page(page)\n",
    "            layout = device.get_result()\n",
    "            results = []\n",
    "            get_objs(layout, results)\n",
    "            for r in results:\n",
    "#                print(r)\n",
    "                posX1 = r['bbox'][0]\n",
    "                posY1 = r['bbox'][1]\n",
    "                #posX2 = r['bbox'][2]\n",
    "                posY2 = r['bbox'][3]\n",
    "                height = posY2 - posY1\n",
    "                posYCenter = math.floor(posY1 + height / 2)\n",
    "                # ',' '%' ' ' を除外\n",
    "                text = r['text'].replace(',', '').replace('%', '')\n",
    "                text = text.replace(' ', '')\n",
    "                # '(' or ')' -> SPLITWORD\n",
    "                text = text.replace(')', SPLITWORD).replace('(', SPLITWORD)\n",
    "                text = text.replace('\\n', '')\n",
    "                pdfList.append(\n",
    "                    {\n",
    "                    \"posX\" : math.floor(posX1), \n",
    "                    \"posY\" : posYCenter, \n",
    "                    \"height\" : math.floor(height), \n",
    "                    \"text\" : text\n",
    "                    }\n",
    "                )\n",
    "                posYSet.add(posYCenter)\n",
    "\n",
    "            # read only TopPage\n",
    "            break\n",
    "    # sort\n",
    "    # 左から順番にデータを読むため、ソートする\n",
    "    pdfList = sorted(pdfList, key=lambda x:x['posX'])\n",
    "\n",
    "    # 同じY座標のデータ(閾値あり)は一つに統一する\n",
    "    # x, height は最初に見つかった文字のサイズ\n",
    "    mergePdfList = []\n",
    "    range = 5.0\n",
    "    for y in posYSet:\n",
    "        _addDict = {}\n",
    "        isFind = False\n",
    "#        print(\"Target Position \" + str(y))\n",
    "        for l in pdfList:\n",
    "            if l['posY'] >= y - range and l['posY'] <= y + range:\n",
    "#                print(l['text'])\n",
    "                if not isFind:\n",
    "                   _addDict = l.copy()\n",
    "                   isFind = True\n",
    "                else:\n",
    "                    _addDict[\"text\"] = _addDict[\"text\"] + SPLITWORD + l['text']\n",
    "        mergePdfList.append(_addDict)\n",
    "    # sort\n",
    "    mergePdfList = sorted(mergePdfList, key=lambda x:x['posY'], reverse=True)\n",
    "\n",
    "    return mergePdfList\n",
    "\n",
    "def parse(filePath, type):\n",
    "#    print(\"parse start : \" + filePath)\n",
    "    try:\n",
    "        pdfList = readPDF(filePath, type)\n",
    "        #print(pdfList)\n",
    "    except:\n",
    "        return \"file open error... : \" + filePath, False\n",
    "    \n",
    "    modeSokuhouHeader = '別紙'\n",
    "    modeAddHeader = '【追加情報】'\n",
    "    typeAge = 'age'\n",
    "    typeSeriouslyIll = 'seriouslyIll'\n",
    "    # keyword, output Keyword\n",
    "    modeSokuhou = (\n",
    "        ['10歳未満', typeAge],\n",
    "        ['【参考】　重症者の属性', typeSeriouslyIll]\n",
    "    )\n",
    "\n",
    "    modeAdd = (\n",
    "        ['重症者の属性', typeSeriouslyIll],\n",
    "    )\n",
    "\n",
    "    isAdd = False\n",
    "    mode = list()\n",
    "    for l in pdfList:\n",
    "        text = l['text']\n",
    "        if modeSokuhouHeader in text:\n",
    "            mode = copy.deepcopy(modeSokuhou)\n",
    "            break\n",
    "        elif modeAddHeader in text:\n",
    "            isAdd = True\n",
    "            mode = copy.deepcopy(modeAdd)\n",
    "            break\n",
    "\n",
    "    if len(mode) <= 0:\n",
    "        return \"miss match header... : \" + filePath, False\n",
    "\n",
    "    # date\n",
    "    _date = \"\"\n",
    "    for l in pdfList:\n",
    "        text = l['text']\n",
    "        if '◆令和' in text:\n",
    "            _date = jaconv.z2h(text, kana=False, ascii=False, digit=True)\n",
    "            _date = _date.replace('◆', '')\n",
    "            _date = _date[:_date.find('日') + 1]\n",
    "            _date = janera.strptime(_date, \"%-E%-kO年%-km月%-kd日\")\n",
    "            _date = _date[0].strftime('%Y%m%d')\n",
    "            break\n",
    "\n",
    "    if len(_date) <= 0:\n",
    "        return \"missing Date... : \" + filePath, False\n",
    "\n",
    "    tmpDict = dict()\n",
    "    tmpHeader = ''\n",
    "    for m in mode:\n",
    "        w = m[0]\n",
    "        type = m[1]\n",
    "        tmpGetList = list()\n",
    "        isFindKeyWord = False\n",
    "        isFindNumber = False\n",
    "        isEnd = False\n",
    "        for l in pdfList:\n",
    "            text = l['text']\n",
    "            # キーワードを探す\n",
    "            if w in text:\n",
    "                isFindKeyWord = True\n",
    "\n",
    "            # キーワード一致後、数字を探す\n",
    "            if isFindKeyWord:\n",
    "                if not isFindNumber:\n",
    "                    tmp = text.replace('(', SPLITWORD).replace(')', '')\n",
    "                    tmp = tmp.split(SPLITWORD)[0]\n",
    "                    if tmp.encode('utf-8').isdigit():\n",
    "                        isFindNumber = True\n",
    "                    elif tmp.isascii() and '.' in tmp:\n",
    "                        isFindNumber = True\n",
    "                    else:\n",
    "                        # ヘッダーを一時保存(PDFごとに列数が異なるため)\n",
    "                        if type == typeAge:\n",
    "                            tmpHeader = text                        \n",
    "\n",
    "                        elif type == typeSeriouslyIll:\n",
    "                            if not w in text:\n",
    "                                tmpHeader = text                        \n",
    "\n",
    "            # 数字を取得、文字が出てきたら終了\n",
    "            if isFindNumber:\n",
    "                # 年代別を取得するとき、以下の通り分割する\n",
    "                # 10歳未満, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 不明\n",
    "                if type == typeAge:\n",
    "                    tmpList = text.split(SPLITWORD)\n",
    "                    tmpHeader = tmpHeader.replace('10歳未満', 'mi')\n",
    "                    tmpHeader = tmpHeader.replace('100歳以上', 'hu')\n",
    "                    tmpHeader = tmpHeader.replace('不明', 'un')\n",
    "                    tmpHeader = tmpHeader.replace('代', '')\n",
    "                    tmpHeader = tmpHeader.replace(SPLITWORD, '')\n",
    "\n",
    "                    idx = 0\n",
    "                    keyList = ['mi', '10', '20', '30', '40', '50', '60', '70', '80', '90', 'hu', 'un']\n",
    "                    for key in keyList:\n",
    "                        if key in tmpHeader:\n",
    "                            tmpGetList.append(tmpList[idx])\n",
    "                            idx += 1\n",
    "                            tmpHeader = tmpHeader[2:]\n",
    "                        else:\n",
    "                            tmpGetList.append('0')\n",
    "                    com.infoMsg(sys._getframe().f_code.co_name, 'Get List : ' +  ' '.join(s for s in tmpGetList))\n",
    "                    # データは1行しかないので、必ず終了\n",
    "                    isEnd = True\n",
    "\n",
    "                # 重症者を取得するとき、以下の通り分割する\n",
    "                # 10歳未満, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 確認中, 男, 女, 確認中\n",
    "                elif type == typeSeriouslyIll:\n",
    "                    tmpList = text.split(SPLITWORD)\n",
    "                    tmpHeader = tmpHeader.replace('10歳未満', 'mi')\n",
    "                    tmpHeader = tmpHeader.replace('100', 'hu')\n",
    "                    tmpHeader = tmpHeader.replace('確認中', 'u1', 1)\n",
    "                    tmpHeader = tmpHeader.replace('確認中', 'u2', 1)\n",
    "                    tmpHeader = tmpHeader.replace('男', 'ma')\n",
    "                    tmpHeader = tmpHeader.replace('女', 'fe')\n",
    "                    tmpHeader = tmpHeader.replace('代', '')\n",
    "                    tmpHeader = tmpHeader.replace(SPLITWORD, '')\n",
    "                    #print(tmpHeader)\n",
    "                            \n",
    "                    idx = 0\n",
    "                    keyList = ['mi', '10', '20', '30', '40', '50', '60', '70', '80', '90', 'hu', 'u1', 'ma', 'fe', 'u2']\n",
    "                    for key in keyList:\n",
    "                        if key in tmpHeader:\n",
    "                            tmpGetList.append(tmpList[idx])\n",
    "                            idx += 1\n",
    "                            tmpHeader = tmpHeader[2:]\n",
    "                        else:\n",
    "                            tmpGetList.append('0')\n",
    "\n",
    "                    com.infoMsg(sys._getframe().f_code.co_name, 'Get List : ' + ' '.join(s for s in tmpGetList))\n",
    "                    # データは1行しかないので、必ず終了\n",
    "                    isEnd = True\n",
    "                \n",
    "                # 今のところここは通らない\n",
    "                else:\n",
    "                    tmpList = text.split(SPLITWORD)\n",
    "                    for tmp in tmpList:\n",
    "                        if tmp.encode('utf-8').isdigit():\n",
    "                            tmpGetList.append(tmp)\n",
    "                        elif tmp.isascii() and '.' in tmp:\n",
    "                            tmpGetList.append(tmp)\n",
    "                        else:\n",
    "                            isEnd = True\n",
    "            if isEnd:\n",
    "                break\n",
    "        tmpDict[w] = tmpGetList\n",
    "\n",
    "    # output \n",
    "    retData = '{'\n",
    "    retData += '\"date\" : \"' + _date + '\", '\n",
    "    retData += '\"isAdd\" : \"' + str(isAdd) + '\", '\n",
    "    for m in mode:\n",
    "        key = m[0]\n",
    "        outputKey = m[1]\n",
    "        tmpDict[key]\n",
    "        retData += '\"' + outputKey + '\" : \"' + ','.join(tmpDict[key]) + '\", '\n",
    "    retData = retData[:-2]\n",
    "    retData = retData + '}'\n",
    "    return retData, True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20211228_214953\tINFO\t[main] Start\n",
      "\n",
      "[Start]20211228214953\n",
      "\n",
      "20211228_214953\tINFO\t[getSettingData] SaveDir : c:\\Users\\niamu\\Documents\\#WorkSpace\\ReadCovid-19/\n",
      "20211228_214953\tINFO\t[main] {\"[0]\": \"c:\\\\Users\\\\niamu\\\\Documents\\\\#WorkSpace\\\\ReadCovid-19/\", \"[a]\": \"True\", \"[b]\": \"list\", \"[B]\": \"data\", \"[c]\": \"dataList.json\", \"[j]\": \"parsePDF.json\", \"[o]\": \"parse_DATE.log\"}\n",
      "20211228_214953\tINFO\t[main] Base File : list/dataList.json\n",
      "20211228_214953\tINFO\t[main] Save File : list/parsePDF.json\n",
      "20211228_214953\tINFO\t[main] Log File : list/parse_20211228214953.log\n",
      "20211228_214953\tINFO\t[parse] Get List : 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0\n",
      "20211228_214953\tINFO\t[main] Parse PDF : 20211228_1228-20-02.pdf  1\n",
      "20211228_214954\tINFO\t[parse] Get List : 0 0 0 0 0 2 0 0 0 0 0 0 2 0 0\n",
      "20211228_214954\tINFO\t[main] Parse PDF : corona2758.files2758-2.pdf  2\n",
      "20211228_214959\tINFO\t[parse] Get List : 2 5 16 8 6 6 2 1 0 0 0 0\n",
      "20211228_214959\tINFO\t[main] Parse PDF : corona2758.files2758.pdf  3\n",
      "20211228_215003\tINFO\t[parse] Get List : 1 3 13 2 6 6 0 1 3 0 0 0\n",
      "20211228_215003\tINFO\t[main] Parse PDF : 20211228_1228-20-01.pdf  4\n",
      "20211228_215004\tINFO\t[main] Get Size :4\n",
      "20211228_215004\tINFO\t[main] End\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    com = comFunction.common()  \n",
    "    com.infoMsg(sys._getframe().f_code.co_name, 'Start')\n",
    "\n",
    "    #設定ファイルから必要な情報を取得する\n",
    "    settingDict = dict()\n",
    "    tagSaveDir = '[0]'\n",
    "    #タグ\n",
    "    tagDebug = '[a]'\n",
    "    tagSaveFolder = '[b]'\n",
    "    tagLoadPDFFolder = '[B]'\n",
    "    tagLoadFileName = '[c]'\n",
    "    tagSaveFileName = '[j]'\n",
    "    tagParseLogName = '[o]'\n",
    "\n",
    "    settingDict = com.getSettingData([\n",
    "        tagSaveDir,\n",
    "        tagDebug,\n",
    "        tagSaveFolder,\n",
    "        tagLoadPDFFolder,\n",
    "        tagLoadFileName,\n",
    "        tagSaveFileName,\n",
    "        tagParseLogName\n",
    "        ])    \n",
    "    com.infoMsg(sys._getframe().f_code.co_name, json.dumps(settingDict))\n",
    "\n",
    "    if len(settingDict) <= 0:\n",
    "        com.errMsg(sys._getframe().f_code.co_name, 'SettingData is none...')\n",
    "        return\n",
    "\n",
    "    if settingDict[tagDebug] == 'true':\n",
    "        com.setDebug(True)\n",
    "    else:\n",
    "        com.setDebug(False)\n",
    "    # Directory    \n",
    "    _saveDir = settingDict[tagSaveDir]\n",
    "    # Folder\n",
    "    _saveFolder = _saveDir + settingDict[tagSaveFolder]\n",
    "    _loadPDFFolder = _saveDir + settingDict[tagLoadPDFFolder]\n",
    "    # File\n",
    "    _loadFileName = settingDict[tagLoadFileName]\n",
    "    _saveFileName = settingDict[tagSaveFileName]\n",
    "    _parseLogName = settingDict[tagParseLogName]\n",
    "    \n",
    "    if len(_saveFolder) <= 0:\n",
    "        com.errorMsg(sys._getframe().f_code.co_name, 'Image data storage folder is None!')\n",
    "        return  \n",
    "\n",
    "    baseFile =_saveFolder + \"/\" + _loadFileName\n",
    "    com.infoMsg(sys._getframe().f_code.co_name, 'Base File : ' + baseFile)\n",
    "\n",
    "    saveFile =_saveFolder + \"/\" + _saveFileName\n",
    "    com.infoMsg(sys._getframe().f_code.co_name, 'Save File : ' + saveFile)\n",
    "    \n",
    "    _parseLogName = _parseLogName.replace('DATE', uf.getNowTime())\n",
    "    logFile =_saveFolder + \"/\" + _parseLogName\n",
    "    com.infoMsg(sys._getframe().f_code.co_name, 'Log File : ' + logFile)\n",
    "    \n",
    "    with open(logFile, mode='w') as f:\n",
    "        uf.fileWrite(f, uf.getNowTime() + '\\n') \n",
    "\n",
    "    # ファイルを開く\n",
    "    updateList = list()\n",
    "    parseList = list()\n",
    "    with open(baseFile, mode='r') as f:\n",
    "        cnt = 0\n",
    "        for line in f:\n",
    "            if len(line) <= 0:\n",
    "                com.infoMsg(sys._getframe().f_code.co_name, 'Size Zero')\n",
    "                continue\n",
    "            if not ( set(('{', '}')) <= set(line)):\n",
    "                com.infoMsg(sys._getframe().f_code.co_name, 'Not Json Format :' + line)\n",
    "                continue\n",
    "\n",
    "            l = line\n",
    "            j = json.loads(line)\n",
    "            type = j['type']\n",
    "            fileName = j['name']\n",
    "            isParse = j['isParse']\n",
    "            if isParse == \"False\":\n",
    "                _data, isGet = parse(_loadPDFFolder + \"/\" + fileName, type)\n",
    "                with open(logFile, mode='a') as flog:\n",
    "                    uf.fileWrite(flog, uf.getNowTime() + \"\\t\" + fileName + \"\\t\" + _data  + '\\n')                 \n",
    "                if not isGet:\n",
    "                    continue\n",
    "                parseList.append(_data + \"\\n\")\n",
    "                cnt += 1\n",
    "                com.infoMsg(sys._getframe().f_code.co_name, 'Parse PDF : ' + fileName + '  ' + str(cnt))\n",
    "                l = l.replace('\"isParse\" : \"False\"', '\"isParse\" : \"True\"')\n",
    "               \n",
    "            updateList.append(l)\n",
    "\n",
    "        com.infoMsg(sys._getframe().f_code.co_name, 'Get Size :' + str(cnt))\n",
    "\n",
    "    # ファイル更新\n",
    "    with open(baseFile, mode='w') as f:\n",
    "        for line in updateList:\n",
    "                uf.fileWrite(f, line)\n",
    "\n",
    "    # パースしたデータを追加\n",
    "    with open(saveFile, mode='a') as f:\n",
    "        for line in parseList:\n",
    "                uf.fileWrite(f, line)\n",
    "    # 重複データ削除\n",
    "    uf.fileDataSlim(saveFile) \n",
    "\n",
    "    com.infoMsg(sys._getframe().f_code.co_name, 'End')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f58e4e82543d0cd2d619c0cff608aeecaf29525f81c9c30d530b5f9f1bf488f9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
